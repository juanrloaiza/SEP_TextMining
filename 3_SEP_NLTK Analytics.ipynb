{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the dataset that includes the clean words, but not lemmatized yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for f in os.listdir('sep_articles_clean/'):\n",
    "    with open('sep_articles_clean/' + f) as raw_text:\n",
    "        dataset.append(ast.literal_eval(raw_text.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Proper Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count each proper noun in the dataset and get its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency_counter = defaultdict(int)\n",
    "\n",
    "for text in dataset:\n",
    "    for sentence in text:\n",
    "        for word in sentence:\n",
    "            if word[1] == 'NNP':\n",
    "                if len(word[0]) > 2:\n",
    "                    frequency_counter[word[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = pd.DataFrame.from_dict(frequency_counter, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>God</th>\n",
       "      <td>19423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aristotle</th>\n",
       "      <td>9132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kant</th>\n",
       "      <td>7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plato</th>\n",
       "      <td>4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hume</th>\n",
       "      <td>4007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell</th>\n",
       "      <td>3565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locke</th>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leibniz</th>\n",
       "      <td>3275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lewis</th>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frege</th>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Socrates</th>\n",
       "      <td>2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mill</th>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Descartes</th>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newton</th>\n",
       "      <td>2076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rawls</th>\n",
       "      <td>2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theory</th>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suppose</th>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smith</th>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "God         19423\n",
       "Aristotle    9132\n",
       "Kant         7732\n",
       "Plato        4502\n",
       "Hume         4007\n",
       "John         3680\n",
       "Russell      3565\n",
       "Locke        3465\n",
       "Leibniz      3275\n",
       "Lewis        3145\n",
       "Frege        2308\n",
       "Socrates     2277\n",
       "Mill         2256\n",
       "Descartes    2137\n",
       "Newton       2076\n",
       "Rawls        2069\n",
       "Theory       2048\n",
       "Suppose      2033\n",
       "Philosophy   1992\n",
       "Smith        1957"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies.sort_values(0, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an interesting first approximation, but has several flaws.\n",
    "\n",
    "* It does not consider names and last names as one proper noun, but separates them. This is why \"John\" is among the most mentioned names. A possible solution would be to eliminate first names and only take the last names, but this would entail problems with, for instances, \"James.\"\n",
    "* Proper nouns also include things like \"Philosophy\" here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for f in os.listdir('sep_articles/'):\n",
    "    with open('sep_articles/' + f) as raw_text:\n",
    "        dataset.append(raw_text.read().decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_items = []\n",
    "for text in dataset:\n",
    "    doc = nlp(text)\n",
    "    labels = [x.label_ for x in doc.ents]\n",
    "    items = [x.text for x in doc.ents if x.label_ == 'PERSON']\n",
    "    all_items += items\n",
    "    all_labels += labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'PERSON': 3018, u'CARDINAL': 1899, u'ORG': 1818, u'DATE': 1386, u'ORDINAL': 614, u'GPE': 583, u'NORP': 492, u'WORK_OF_ART': 76, u'LOC': 72, u'PRODUCT': 64, u'FAC': 51, u'MONEY': 36, u'LANGUAGE': 25, u'EVENT': 24, u'LAW': 18, u'PERCENT': 4, u'TIME': 4, u'QUANTITY': 3})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Leibniz', 212), (u'Monadologie', 10), (u'Syst\\xe8me', 6), (u'Russell', 4), (u'Judas', 4), (u'Principes de la Nature et de la Grace', 4), (u'Arnauld', 4), (u'Jesus', 3), (u'Burnett', 3), (u'Remond', 2), (u'CP:31', 2), (u'Charles Hugony', 2), (u'Logicarum A.VI.iv.a.624\\u2013630', 1), (u'Garber 2009', 1), (u'Hartz 2007', 1), (u'Biber', 1), (u'Antoine\\nArnauld', 1), (u'Simon Foucher', 1), (u'AG:138', 1), (u\"Bertrand Russell's\", 1), (u'Works', 1), (u'Plato', 1), (u'Esoteric', 1), (u'Geometrical', 1), (u'AG:215', 1), (u'AG:214', 1), (u'Essais de', 1), (u'Nelson', 1), (u'Grace', 1), (u'De Obligatione Credendi', 1), (u'Adams', 1), (u'Nicolas Remond', 1), (u'G. W. Leibniz', 1), (u'Confessio Philosophi', 1), (u'AG:213', 1), (u'Russell 1945', 1), (u'Pierre Bayle', 1), (u'Esoteric Form', 1), (u'Kant', 1), (u'Sophia', 1), (u'Essay', 1), (u'Curley', 1), (u'Jesuit', 1), (u'Syst\\xe8me Nouveau\\n\\n\\n', 1), (u'Spinoza', 1), (u'De Notionibus', 1), (u'Notionum Praeparanda A.VI.iv.a.630\\u2013635', 1), (u'Schepers', 1), (u'M. Bayle', 1), (u'Monad', 1), (u'Summary\\n\\n\\n', 1), (u'Preface', 1), (u'Euclid', 1), (u'Cartesians', 1), (u'Batavis', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(items).most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
