# Text mining on the _Stanford Encyclopedia of Philosophy_

This repository includes a series of Jupyter Notebooks that sketch a data analysis project based on the _Stanford Encyclopedia of Philosophy_. It includes the following notebooks:

* Scraper - Gets the articles from the SEP and saves them to disk (raw).
* Preprocessing - Using NLTK, it processes the raw data into several types of data that can be analyzed.
* Analytics - Runs a series of exploratory analyses regarding word frequencies and NER recognition.
* Topic Modeling - Implements LDA models for topic modeling.
* SciKitLearn - Implements K Means clustering using SciKit Learn.

As of the last update, this is just a fun project and a proof of concept. It still requires a lot of work both technically and intellectually for it to become a real project. For now, this is only intended with educational purposes. No data is included in this repository. 

## Technical to do
These are problems that need to be fixed on the technical side of the project.
* Finish the technical to do.

## Academic to do
These are issues to be addressed if this were to become a serious academic project.
* Ethics approval for Internet Based Research.
* Ask for proper permission to analyze the SEP.
* Validate the topics using independent raters.
